{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements and original csv files to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, BioGptForCausalLM\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to your file locations\n",
    "file_location_discharge = 'C:/3163dataset/discharge.csv.gz'\n",
    "file_location_radiology = 'C:/3163dataset/radiology.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_df = pd.read_csv(file_location_discharge, compression='gzip')\n",
    "radiology_df = pd.read_csv(file_location_radiology, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarisation using Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioGPT model summariser\n",
    "# min_length and max_length by default is 200 and 1025 respectively\n",
    "def biogpt(note, min_length=200, max_length=1025):\n",
    "    model_name = \"microsoft/biogpt\"\n",
    "    model = BioGptForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    inputs = tokenizer.encode(\"summarize: \" + note, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# BART model summariser\n",
    "# min_length and max_length by default is 200 and 500 respectively\n",
    "def bart(note, min_length=200, max_length=500):\n",
    "    model_name = \"facebook/bart-large-cnn\"\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    inputs = tokenizer.encode(\"summarize: \" + note, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# To summarise discharge note -> run biogpt then bart\n",
    "def summarise_discharge(note):\n",
    "    summarised = biogpt(note)\n",
    "    summarised = bart(summarised)\n",
    "    return summarised\n",
    "\n",
    "# To summarise radiology note -> run biogpt then bart (with less character length)\n",
    "def summarise_radiology(note):\n",
    "    summarised = biogpt(note, min_length=200, max_length=500)\n",
    "    summarised = bart(summarised, min_length=100, max_length=200)\n",
    "    return summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Integrate discharge and radiology sections\n",
    "#discharge_df['summarised'] = discharge_df['text'].apply(summarise_discharge)\n",
    "#radiology_df['summarised'] = radiology_df['text'].head(1).apply(summarise_radiology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name and DOB generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name generation for every record in discharge and radiology\n",
    "fake = Faker()\n",
    "subject_ids = discharge_df['subject_id'].unique()\n",
    "name_map = {subject_id: fake.name() for subject_id in subject_ids}\n",
    "discharge_df['name'] = discharge_df['subject_id'].map(name_map)\n",
    "radiology_df['name'] = radiology_df['subject_id'].map(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOB generation for every record in discharge and radiology\n",
    "def generate_random_dob(start_year=1930, end_year=2020):\n",
    "    start_date = datetime(year=start_year, month=1, day=1)\n",
    "    end_date = datetime(year=end_year, month=12, day=31)\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    random_date = start_date + timedelta(days=random_number_of_days)\n",
    "    return random_date\n",
    "subject_ids = discharge_df['subject_id'].unique()\n",
    "dob_map = {subject_id: generate_random_dob() for subject_id in subject_ids}\n",
    "discharge_df['dob'] = discharge_df['subject_id'].map(dob_map)\n",
    "radiology_df['dob'] = radiology_df['subject_id'].map(dob_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complaint and patient sex regex for DISCHARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chief complaint for every record\n",
    "def extract_complaint(note):\n",
    "    chief_complaint_match = re.search(r'(?:Chief|Present|Main)?\\s*Complaint[:\\s]*(.*?)(?:Major Surgical|History of Present Illness:|$)', note, re.IGNORECASE | re.DOTALL)\n",
    "    if chief_complaint_match:\n",
    "        return chief_complaint_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "discharge_df['complaint'] = discharge_df['text'].apply(extract_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patient sex for every record\n",
    "def extract_patient_sex(note):\n",
    "    patient_sex = re.search(r'Sex:\\s*(\\w)', note, re.IGNORECASE)\n",
    "    if patient_sex:\n",
    "        patient_sex = patient_sex.group(1)\n",
    "        if patient_sex == 'F' or patient_sex == 'f':\n",
    "            patient_sex = 'Female'\n",
    "        elif patient_sex == 'M' or patient_sex == 'm':\n",
    "            patient_sex = 'Male'\n",
    "        return patient_sex\n",
    "    else:\n",
    "        return None\n",
    "discharge_df['patient_sex'] = discharge_df['text'].apply(extract_patient_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examination regex for RADIOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract examination for every record\n",
    "def extract_radiology_examination(note):\n",
    "    examination = re.search(r'EXAMINATION:(.*?)INDICATION:', note, re.IGNORECASE | re.DOTALL)\n",
    "    if examination:\n",
    "        examination = examination.group(1).strip()\n",
    "        return examination\n",
    "    else:\n",
    "        return None\n",
    "radiology_df['examination'] = radiology_df['text'].apply(extract_radiology_examination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
