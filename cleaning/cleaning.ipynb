{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c697b791",
   "metadata": {},
   "source": [
    "# Structuring and Cleaning\n",
    "\n",
    "---\n",
    "\n",
    "Within this notebook I will be performing cleaning and structuring using python\n",
    "and some libraries and packages from online. I will keep a list of the packages I \n",
    "use as well as the important notes (insert below). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca6279",
   "metadata": {},
   "source": [
    "## Important Notes \n",
    "\n",
    "- **pandas:** for mathematical calculations and arrays.\n",
    "- **re:** for regex pattern matching and sequence classification.\n",
    "- **torch:** tensor operations, efficiency and mainly neural network building blocks. \n",
    "- **torch.nn:** neural network building blocks.\n",
    "- **transformers:** provides pre-trained models \n",
    "\n",
    "---\n",
    "\n",
    "### nn.Module\n",
    "\n",
    "In PyTorch, nn.Module is a base class for all neural network modules. It is a fundamental building block for creating neural network architectures. When you create a custom neural network in PyTorch, you typically subclass nn.Module and define the network's layers and operations within this class.\n",
    "\n",
    "### nn.Dropout\n",
    "\n",
    "The `nn.Dropout` layer is a regularization technique commonly used in neural networks to prevent overfitting. It works by randomly setting a fraction of input units to zero during training, which helps prevent the network from relying too much on any particular set of features. \n",
    "\n",
    "The argument `0.1` in `nn.Dropout(0.1)` specifies the probability of dropping out each neuron during training. In this case, `0.1` means that each neuron in the input will be set to zero with a probability of 0.1 (or 10%) during each forward pass through the network. \n",
    "\n",
    "During inference (i.e., when the model is used to make predictions), dropout is typically turned off or scaled appropriately to ensure that the expected output remains the same. This scaling is often achieved automatically in PyTorch when using `nn.Dropout` with the `model.eval()` mode.\n",
    "\n",
    "In summary, `nn.Dropout(0.1)` introduces random dropout with a probability of 0.1 during training to prevent \n",
    "overfitting and improve the generalization ability of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbe563bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: can ignore the UserWarning as it is an internal pytorch issue\n",
    "# import important libraries and packages\n",
    "\n",
    "import pandas as pd \n",
    "import re \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertModel, BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "650fd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the Data\n",
    "df = pd.read_csv(\"discharge.csv\", nrows=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3049dcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032-DS-21</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>DS</td>\n",
       "      <td>21</td>\n",
       "      <td>2180-05-07 00:00:00</td>\n",
       "      <td>2180-05-09 15:26:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032-DS-22</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>DS</td>\n",
       "      <td>22</td>\n",
       "      <td>2180-06-27 00:00:00</td>\n",
       "      <td>2180-07-01 10:15:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032-DS-23</td>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>DS</td>\n",
       "      <td>23</td>\n",
       "      <td>2180-07-25 00:00:00</td>\n",
       "      <td>2180-07-25 21:42:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032-DS-24</td>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>DS</td>\n",
       "      <td>24</td>\n",
       "      <td>2180-08-07 00:00:00</td>\n",
       "      <td>2180-08-10 05:43:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000084-DS-17</td>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>DS</td>\n",
       "      <td>17</td>\n",
       "      <td>2160-11-25 00:00:00</td>\n",
       "      <td>2160-11-25 15:09:00</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id  subject_id   hadm_id note_type  note_seq  \\\n",
       "0  10000032-DS-21    10000032  22595853        DS        21   \n",
       "1  10000032-DS-22    10000032  22841357        DS        22   \n",
       "2  10000032-DS-23    10000032  29079034        DS        23   \n",
       "3  10000032-DS-24    10000032  25742920        DS        24   \n",
       "4  10000084-DS-17    10000084  23052089        DS        17   \n",
       "\n",
       "             charttime            storetime  \\\n",
       "0  2180-05-07 00:00:00  2180-05-09 15:26:00   \n",
       "1  2180-06-27 00:00:00  2180-07-01 10:15:00   \n",
       "2  2180-07-25 00:00:00  2180-07-25 21:42:00   \n",
       "3  2180-08-07 00:00:00  2180-08-10 05:43:00   \n",
       "4  2160-11-25 00:00:00  2160-11-25 15:09:00   \n",
       "\n",
       "                                                text  \n",
       "0   \\nName:  ___                     Unit No:   _...  \n",
       "1   \\nName:  ___                     Unit No:   _...  \n",
       "2   \\nName:  ___                     Unit No:   _...  \n",
       "3   \\nName:  ___                     Unit No:   _...  \n",
       "4   \\nName:  ___                    Unit No:   __...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d85a7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nName:  ___                     Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___\\n \\nChief Complaint:\\nWorsening ABD distension and pain \\n \\nMajor Surgical or Invasive Procedure:\\nParacentesis\\n\\n \\nHistory of Present Illness:\\n___ HCV cirrhosis c/b ascites, hiv on ART, h/o IVDU, COPD, \\nbioplar, PTSD, presented from OSH ED with worsening abd \\ndistension over past week.  \\nPt reports self-discontinuing lasix and spirnolactone ___ weeks \\nago, because she feels like \"they don\\'t do anything\" and that \\nshe \"doesn\\'t want to put more chemicals in her.\" She does not \\nfollow Na-restricted diets. In the past week, she notes that she \\nhas been having worsening abd distension and discomfort. She \\ndenies ___ edema, or SOB, or orthopnea. She denies f/c/n/v, d/c, \\ndysuria. She had food poisoning a week ago from eating stale \\ncake (n/v 20 min after food ingestion), which resolved the same \\nday. She denies other recent illness or sick contacts. She notes \\nthat she has been noticing gum bleeding while brushing her teeth \\nin recent weeks. she denies easy bruising, melena, BRBPR, \\nhemetesis, hemoptysis, or hematuria.  \\nBecause of her abd pain, she went to OSH ED and was transferred \\nto ___ for further care. Per ED report, pt has brief period of \\nconfusion - she did not recall the ultrasound or bloodwork at \\nosh. She denies recent drug use or alcohol use. She denies \\nfeeling confused, but reports that she is forgetful at times.  \\nIn the ED, initial vitals were 98.4 70 106/63 16 97%RA  \\nLabs notable for ALT/AST/AP ___ ___: ___, \\nTbili1.6, WBC 5K, platelet 77, INR 1.6  \\n\\n \\nPast Medical History:\\n1. HCV Cirrhosis  \\n2. No history of abnormal Pap smears.  \\n3. She had calcification in her breast, which was removed  \\npreviously and per patient not, it was benign.  \\n4. For HIV disease, she is being followed by Dr. ___ Dr.  \\n___.  \\n5. COPD  \\n6. Past history of smoking.  \\n7. She also had a skin lesion, which was biopsied and showed  \\nskin cancer per patient report and is scheduled for a complete  \\nremoval of the skin lesion in ___ of this year.  \\n8. She also had another lesion in her forehead with purple  \\ndiscoloration. It was biopsied to exclude the possibility of  \\n___\\'s sarcoma, the results is pending.  \\n9. A 15 mm hypoechoic lesion on her ultrasound on ___  \\nand is being monitored by an MRI.  \\n10. History of dysplasia of anus in ___.  \\n11. Bipolar affective disorder, currently manic, mild, and PTSD. \\n \\n12. History of cocaine and heroin use.  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe a total of five siblings, but she is not  \\ntalking to most of them. She only has one brother that she is in \\n \\ntouch with and lives in ___. She is not aware of any  \\nknown GI or liver disease in her family.  \\nHer last alcohol consumption was one drink two months ago. No  \\nregular alcohol consumption. Last drug use ___ years ago. She  \\nquit smoking a couple of years ago.  \\n\\n \\nPhysical Exam:\\nVS: 98.1 107/61 78 18 97RA  \\nGeneral: in NAD  \\nHEENT: CTAB, anicteric sclera, OP clear  \\nNeck: supple, no LAD  \\nCV: RRR,S1S2, no m/r/g  \\nLungs: CTAb, prolonged expiratory phase, no w/r/r  \\nAbdomen: distended, mild diffuse tenderness, +flank dullness, \\ncannot percuss liver/spleen edge ___ distension  \\nGU: no foley  \\nExt: wwp, no c/e/e, + clubbing  \\nNeuro: AAO3, converse normally, able to recall 3 times after 5 \\nminutes, CN II-XII intact  \\n\\nDischarge:\\n\\nPHYSICAL EXAMINATION:  \\nVS: 98 105/70 95\\nGeneral: in NAD  \\nHEENT: anicteric sclera, OP clear  \\nNeck: supple, no LAD  \\nCV: RRR,S1S2, no m/r/g  \\nLungs: CTAb, prolonged expiratory phase, no w/r/r  \\nAbdomen: distended but improved, TTP in RUQ, \\nGU: no foley  \\nExt: wwp, no c/e/e, + clubbing  \\nNeuro: AAO3,  CN II-XII intact  \\n\\n \\nPertinent Results:\\n___ 10:25PM   GLUCOSE-109* UREA N-25* CREAT-0.3* SODIUM-138 \\nPOTASSIUM-3.4 CHLORIDE-105 TOTAL CO2-27 ANION GAP-9\\n___ 10:25PM   estGFR-Using this\\n___ 10:25PM   ALT(SGPT)-100* AST(SGOT)-114* ALK PHOS-114* \\nTOT BILI-1.6*\\n___ 10:25PM   LIPASE-77*\\n___ 10:25PM   ALBUMIN-3.3*\\n___ 10:25PM   WBC-5.0# RBC-4.29 HGB-14.3 HCT-42.6 MCV-99* \\nMCH-33.3* MCHC-33.5 RDW-15.7*\\n___ 10:25PM   NEUTS-70.3* LYMPHS-16.5* MONOS-8.1 EOS-4.2* \\nBASOS-0.8\\n___ 10:25PM   PLT COUNT-71*\\n___ 10:25PM   ___ PTT-30.9 ___\\n___ 10:25PM   ___\\n.\\n\\nCXR: No acute cardiopulmonary process.  \\nU/S:  \\n1. Nodular appearance of the liver compatible with cirrhosis. \\nSigns of portal  \\nhypertension including small amount of ascites and splenomegaly. \\n \\n2. Cholelithiasis.  \\n3. Patent portal veins with normal hepatopetal flow.  \\nDiagnostic para attempted in the ED, unsuccessful.  \\nOn the floor, pt c/o abd distension and discomfort.\\n \\nBrief Hospital Course:\\n___ HCV cirrhosis c/b ascites, hiv on ART, h/o IVDU, COPD, \\nbioplar, PTSD, presented from OSH ED with worsening abd \\ndistension over past week and confusion.  \\n\\n# Ascites - p/w worsening abd distension and discomfort for last \\nweek. likely ___ portal HTN given underlying liver disease, \\nthough no ascitic fluid available on night of admission. No \\nsigns of heart failure noted on exam. This was ___ to med \\nnon-compliance and lack of diet restriction. SBP negative\\ndiuretics:  \\n> Furosemide 40 mg PO DAILY  \\n> Spironolactone 50 mg PO DAILY, chosen over the usual 100mg \\ndose d/t K+ of 4.5.   \\n CXR was wnl, UA negative, Urine culture blood culture negative. \\n \\nPt was losing excess fluid appropriately with stable lytes on \\nthe above regimen. Pt was scheduled with current PCP for \\n___ check upon discharge.   \\nPt was scheduled for new PCP with Dr. ___ at ___ and \\nfollow up in Liver clinic to schedule outpatient screening EGD \\nand ___.   \\n \\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Furosemide 20 mg PO DAILY \\n2. Spironolactone 50 mg PO DAILY \\n3. Albuterol Inhaler 2 PUFF IH Q4H:PRN wheezing, SOB \\n4. Raltegravir 400 mg PO BID \\n5. Emtricitabine-Tenofovir (Truvada) 1 TAB PO DAILY \\n6. Nicotine Patch 14 mg TD DAILY \\n7. Ipratropium Bromide Neb 1 NEB IH Q6H SOB \\n\\n \\nDischarge Medications:\\n1. Albuterol Inhaler 2 PUFF IH Q4H:PRN wheezing, SOB \\n2. Emtricitabine-Tenofovir (Truvada) 1 TAB PO DAILY \\n3. Furosemide 40 mg PO DAILY \\nRX *furosemide 40 mg 1 tablet(s) by mouth Daily Disp #*30 Tablet \\nRefills:*3\\n4. Ipratropium Bromide Neb 1 NEB IH Q6H SOB \\n5. Nicotine Patch 14 mg TD DAILY \\n6. Raltegravir 400 mg PO BID \\n7. Spironolactone 50 mg PO DAILY \\n8. Acetaminophen 500 mg PO Q6H:PRN pain \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nAscites from Portal HTN\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nDear Ms. ___,\\nIt was a pleasure taking care of you! You came to us with \\nstomach pain and worsening distension. While you were here we \\ndid a paracentesis to remove 1.5L of fluid from your belly. We \\nalso placed you on you 40 mg of Lasix and 50 mg of Aldactone to \\nhelp you urinate the excess fluid still in your belly. As we \\ndiscussed, everyone has a different dose of lasix required to \\nmake them urinate and it\\'s likely that you weren\\'t taking a high \\nenough dose. Please take these medications daily to keep excess \\nfluid off and eat a low salt diet. You will follow up with Dr. \\n___ in liver clinic and from there have your colonoscopy \\nand EGD scheduled. Of course, we are always here if you need us. \\nWe wish you all the best!\\nYour ___ Team.  \\n \\nFollowup Instructions:\\n___\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data.\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed3954",
   "metadata": {},
   "source": [
    "### Compute Number of Titles\n",
    "\n",
    "To use the code below we need to know how many titles there are in a section of text. This is based off of the \n",
    "number of labels present in the sample text. Below we will: \n",
    "\n",
    "1. define the __regex__ pattern for titles. \n",
    "2. find all the titles matching the pattern. \n",
    "3. remove duplicates and normalise the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4e2c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised Titles: ['HYSICAL EXAMINATION', ' GU', 'H SOB  Discharge Medications', 'scites from Portal HTN Discharge Condition', '   Social History', ' PLACEHOLDERNAME                     Unit No', 'ental Status', 'XII intact  Discharge', ' Tablet Refills', 'RA  General', 'MEDICINE Allergies', 'aracentesis History of Present Illness', ' no LAD  CV', 'XII intact   Pertinent Results', '   Physical Exam', 'in NAD  HEENT', 'S', 'g  Lungs', '  PLACEHOLDERNAME Admission Date', ' clubbing  Neuro', 'AP PLACEHOLDERNAME PLACEHOLDERNAME', 'Name', 'ACEHOLDERNAMEFamily History', 'spleen edge PLACEHOLDERNAME distension  GU', ' SBP negativediuretics', '   Past Medical History', 'H', 'ome Discharge Diagnosis', ' PLACEHOLDERNAME              Discharge Date', '  F Service', 'Activity Status', 'General', ' OP clear  Neck', 'RN pain  Discharge Disposition', ' Discharge Instructions', 'no foley  Ext', '     Medications on Admission', '   Followup Instructions', ' Adverse Drug Reactions Attending', ' Brief Hospital Course', 'orsening ABD distension and pain  Major Surgical or Invasive Procedure', ' VS', 'CXR', 'Level of Consciousness', ' PLACEHOLDERNAME             Sex', 'PLACEHOLDERNAME Chief Complaint', '  PLACEHOLDERNAME Date of Birth', 'r  Abdomen']\n",
      "Number of Labels (num_labels): 48\n"
     ]
    }
   ],
   "source": [
    "# Initialise the text sample\n",
    "text_sample = df['text'][0]\n",
    "\n",
    "# Remove weird characters\n",
    "text_sample = re.sub(r'\\n', '', text_sample)\n",
    "text_sample = re.sub(r'___', 'PLACEHOLDERNAME', text_sample)\n",
    "\n",
    "# Define the title pattern\n",
    "title_pattern = r'(?:(?!PLACEHOLDERNAME).)([A-Za-z\\s]+):'\n",
    "\n",
    "# Find all the titles matching the pattern\n",
    "titles = re.findall(title_pattern, text_sample)\n",
    "\n",
    "# Normalise the titles\n",
    "normalized_titles = list(set(titles))\n",
    "\n",
    "# Display the normalised titles\n",
    "print(\"Normalised Titles:\", normalized_titles)\n",
    "\n",
    "# Define number of labels \n",
    "num_labels = len(normalized_titles)\n",
    "print(\"Number of Labels (num_labels):\", num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aea1dc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up model parameters\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fec4607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for Title Classification\n",
    "\n",
    "class TitleClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(TitleClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049416d",
   "metadata": {},
   "source": [
    "Breaking down each line of the code and understand what it does:\n",
    "\n",
    "```python\n",
    "class TitleClassifier(nn.Module):\n",
    "```\n",
    "- This line defines a new class called `TitleClassifier`, which is a subclass of `nn.Module`. This class will serve as our title classifier neural network model.\n",
    "\n",
    "```python\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "```\n",
    "- This line defines the constructor method `__init__()` for the `TitleClassifier` class. It initializes the class with two parameters: `bert_model` and `num_labels`.\n",
    "- `bert_model`: This parameter is the pre-trained BERT model that will be used for classification.\n",
    "- `num_labels`: This parameter specifies the number of output labels for classification.\n",
    "\n",
    "```python\n",
    "        super(TitleClassifier, self).__init__()\n",
    "```\n",
    "- This line calls the constructor of the superclass `nn.Module` to initialize the `TitleClassifier` class.\n",
    "\n",
    "```python\n",
    "        self.bert = bert_model\n",
    "```\n",
    "- This line assigns the pre-trained BERT model (`bert_model`) to the `bert` attribute of the `TitleClassifier` class. This allows the classifier to use BERT's pre-trained weights and layers.\n",
    "\n",
    "```python\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "```\n",
    "- This line creates a dropout layer with a dropout probability of 0.1 (10%) and assigns it to the `dropout` attribute of the `TitleClassifier` class. Dropout is a regularization technique used to prevent overfitting by randomly setting some output features to zero during training.\n",
    "\n",
    "```python\n",
    "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_labels)\n",
    "```\n",
    "- This line creates a fully connected linear layer (`nn.Linear`) with input size equal to the hidden size of the BERT model (`bert_model.config.hidden_size`) and output size equal to the number of labels (`num_labels`). This layer will be used to classify the input into different categories.\n",
    "\n",
    "```python\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "```\n",
    "- This line defines the forward method for the `TitleClassifier` class. The forward method specifies how input data should be processed through the neural network during the forward pass.\n",
    "\n",
    "```python\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "```\n",
    "- This line passes the input token IDs (`input_ids`) and attention mask (`attention_mask`) to the pre-trained BERT model (`self.bert`) and obtains the model outputs, including the hidden states and pooled output.\n",
    "\n",
    "```python\n",
    "        pooled_output = outputs.pooler_output\n",
    "```\n",
    "- This line extracts the pooled output from the BERT model outputs. The pooled output is a summary representation of the input sequence obtained by applying a pooling operation over the hidden states of the last layer.\n",
    "\n",
    "```python\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "```\n",
    "- This line applies dropout regularization to the pooled output obtained from BERT by passing it through the dropout layer (`self.dropout`). This helps prevent overfitting during training.\n",
    "\n",
    "```python\n",
    "        logits = self.classifier(pooled_output)\n",
    "```\n",
    "- This line passes the dropout output (`pooled_output`) through the linear classifier (`self.classifier`) to obtain the logits, which are unnormalized scores representing the predicted probabilities for each class label.\n",
    "\n",
    "```python\n",
    "        return logits\n",
    "```\n",
    "- Finally, this line returns the logits from the forward pass as the output of the `forward` method. These logits will be used to compute the loss and perform backpropagation during training.\n",
    "\n",
    "Overall, the `TitleClassifier` class defines a neural network model for classifying input sequences into different categories using a pre-trained BERT model for feature extraction and a linear classifier for classification. The model applies dropout regularization to prevent overfitting and returns the logits for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47239b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the BERT Model \n",
    "num_labels = len(normalized_titles)\n",
    "model = TitleClassifer(bert_model, num_labels)\n",
    "\n",
    "# Define loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d3f18",
   "metadata": {},
   "source": [
    "### Create a Training Loop \n",
    "\n",
    "This is where we fine tune and teach the model based on the textual data. \n",
    "We will use `epochs` as iterations and train the model to pick up on the sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad() \n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e994f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    # replacing the underscores with placeholder names\n",
    "    cleaned_text = re.sub(r'___', 'PythonSQL', text)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
